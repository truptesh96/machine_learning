{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scale_data = scaler.fit(data)\n",
    "scaler.transform(data)\n",
    "\n",
    "from sklearn.metricse import \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading Data\n",
    "df = pd.read_csv(\"BankCreditCard.csv\")\n",
    "\n",
    "pandas.read_csv(filepath_or_buffer: Union[str, pathlib.Path, IO[~AnyStr]], \n",
    "                sep=',', delimiter=None, header='infer', names=None, index_col=None, \n",
    "                usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, \n",
    "                engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, \n",
    "                skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, \n",
    "                verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, \n",
    "                date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', \n",
    "                thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, \n",
    "                escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, \n",
    "                delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
    "\n",
    "\n",
    "\n",
    "df.describe()\n",
    "df.info()\n",
    "df.isna().sum()\n",
    "\n",
    "# Variables having NA's\n",
    "def get_na(data): \n",
    "    null_vars = data.isnull().sum()\n",
    "    null_vars = null_vars[null_vars > 0]\n",
    "    if(len(null_vars) > 0):\n",
    "        null_vars.sort_values(inplace=True)\n",
    "        return null_vars\n",
    "    else:\n",
    "        print(\"No column have NA values\")\n",
    "get_na(dataset)\n",
    "\n",
    "# Numerical Variables\n",
    "num_datatypes = ['int32','int64','float64']\n",
    "df_numerics = df.select_dtypes(num_datatypes).columns\n",
    "print(\"Total Numerical Variables\",len(df_numerics))\n",
    "if len(df_numerics) > 0:\n",
    "    print(df_numerics)\n",
    "else:\n",
    "    print(\"No Numerical Variables are present\")\n",
    "\n",
    "# Categorical Variables\n",
    "\n",
    "df_categorical = df.select_dtypes(\"O\").columns\n",
    "print(\"Total Numerical Variables\",len(df_categorical))\n",
    "if len(df_categorical) > 0:\n",
    "    print(df_categorical)\n",
    "else:\n",
    "    print(\"No categorical Variables are present\")\n",
    "\n",
    "#Convert Datatype or Type Casting\n",
    "data['YrSold'] = data['YrSold'].astype(str)\n",
    "\n",
    "# Get NA values and Dictionary iterations\n",
    "ndf = dict(get_na(x_numerics))\n",
    "for x in ndf.keys():\n",
    "   print(x, ndf[x])\n",
    "\n",
    "# Fillna for numerics with loop\n",
    "ndf = dict(get_na(x_numerics))\n",
    "for p in ndf.keys():\n",
    "   x_numerics[p].fillna(x_numerics[p].mean(), inplace = True)\n",
    "\n",
    "# Dropping Columns\n",
    "x.drop('Customer ID', axis = 1, inplace = True)\n",
    "\n",
    "# Skewness Treatment for numerical Variables\n",
    "from scipy.stats import skew\n",
    "    data_num_skew = data_num.apply(lambda x: skew(x.dropna()))\n",
    "    data_num_skew = data_num_skew[data_num_skew > .75]\n",
    "    # apply log + 1 transformation for all numeric features with skewnes over .75\n",
    "    data_num[data_num_skew.index] = np.log1p(data_num[data_num_skew.index])\n",
    "# Checking Skewness\n",
    "data_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); #avoid having the matplotlib verbose informations\n",
    "\n",
    "\n",
    "# Upper Caping and Lower Caping for numerical Attribute\n",
    "def set_caping(column, caping):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    UCL = mean + 3 * std\n",
    "    LCL = mean - 3 * std\n",
    "    if caping == \"both\":\n",
    "        data[column > UCL] = UCL\n",
    "        data[column < LCL] = LCL\n",
    "    elif caping == \"upper\":\n",
    "        data[column > UCL] = UCL\n",
    "    elif caping == \"lower\":\n",
    "        data[column > LCL] = LCL\n",
    "    else:\n",
    "        print(\"Please enter proper value of capping parameter. \\n Possible values:\\tboth\\tupper\\tlower\")\n",
    "\n",
    "set_caping(data[\"age\"], caping = \"both\")\n",
    "data.boxplot(column =\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent\n",
    "new_df_train['Dependents'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA - Linear Descriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Principle Componant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "    x_train,x_test, y_train, y_test = train_test_split(newdata, target_log, test_size = 0.30, random_state=0)\n",
    "    print(\"x_train \",x_train.shape)\n",
    "    print(\"x_test \",x_test.shape)\n",
    "    print(\"y_train \",y_train.shape)\n",
    "    print(\"y_test \",y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "    lm = LinearRegression()\n",
    "    model = lm.fit(x_train,y_train)\n",
    "    predicted = model.predict(x_test)\n",
    "#Evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "    x_train,x_test, y_train, y_test = train_test_split(newdata, target_log, test_size = 0.30, random_state=0)\n",
    "    print(\"x_train \",x_train.shape)\n",
    "    print(\"x_test \",x_test.shape)\n",
    "    print(\"y_train \",y_train.shape)\n",
    "    print(\"y_test \",y_test.shape)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    glm = LogisticRegression()\n",
    "    model = lm.fit(x_train,y_train)\n",
    "    predicted = model.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Function For Logistic Regression Create Summary For Logistic Regression\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle=':')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def get_summary(y_test,predicted):\n",
    "    # Confusion Matrix\n",
    "    conf_mat = confusion_matrix(y_test,predicted)\n",
    "    TP = conf_mat[0,0:1]\n",
    "    FP = conf_mat[0,1:2]\n",
    "    FN = conf_mat[1,0:1]\n",
    "    TN = conf_mat[1,1:2]\n",
    "    \n",
    "    accuracy = (TP+TN)/((FN+FP)+(TP+TN))\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall =  TP / (TP + FN)\n",
    "    \n",
    "    fScore = (2 * recall * precision) / (recall + precision)\n",
    "    auc = roc_auc_score(y_test, predicted)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\",conf_mat)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"Sensitivity :\",sensitivity)\n",
    "    print(\"Specificity :\",specificity)\n",
    "    print(\"Precision:\",precision)\n",
    "    print(\"Recall:\",recall)\n",
    "    print(\"F-score:\",fScore)\n",
    "    print(\"AUC:\",auc)\n",
    "    print(\"ROC curve:\")\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted)\n",
    "    plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.ensemble.RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "model_rf = lm.fit(x_train,y_train)\n",
    "predicted_rf = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series\n",
    "\n",
    "\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada Boost\n",
    "\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost\n",
    "\n",
    "# Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
